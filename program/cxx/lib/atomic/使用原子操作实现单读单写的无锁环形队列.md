# 使用原子操作实现单读单写的无锁环形队列

[![co lin](https://picx.zhimg.com/v2-96e02278016280d6efa74b7e325ba523_l.jpg?source=172ae18b)](https://www.zhihu.com/people/co-lin)

[co lin](https://www.zhihu.com/people/co-lin)

16 人赞同了该文章

FIFO队列是服务器很常见的数据结构，经常被用在生产者消费者模式的程序中，生产者和消费者可以运行在不同的线程，因此队列需要用锁来保证线程安全。但是锁有一定的性能代价，特别是在资源竞争很厉害的时候。

假如我们能对应用场景作一些限制，那么将有可能实现一个健壮的无锁队列，这些限制包括：

- 同时只能有一个写线程和一个读线程。****
- 队列的大小是固定的(有界)，如果队列满了，向它写数据将会失败。

接下来我将使用C11提供的原子操作来实现一个单读单写的无锁环形队列，因为有上面的限制条件，甚至连CAS都不用了，只需要原子的load和store即可。用C++11也可以，它们提供的原子操作是一致的。

下面是队列的定义：

```c
#include <stdlib.h>
#include <stdio.h>
#include <stddef.h>
#include <string.h>
#include <stdbool.h>
#include <stdint.h>
#include <stdatomic.h>
#include <pthread.h>
#include <time.h>

typedef int swr_ele_t;      // 元素

typedef struct swr_queue {  // 队列结构
    atomic_size_t head;
    atomic_size_t tail;
    swr_ele_t *eles;
    size_t size;
    pthread_mutex_t lock;
} swr_queue_t;

// 初始化队列
void swrq_init(swr_queue_t *queue, size_t size) {
    memset(queue, 0, sizeof(*queue));
    queue->size = size + 1;
    queue->eles = (swr_ele_t*)malloc(sizeof(swr_ele_t)*queue->size);
    pthread_mutex_init(&queue->lock, 0);
}

// 释放队列的资源
void swrq_free(swr_queue_t *queue) {
    free(queue->eles);
    pthread_mutex_destroy(&queue->lock);
}

// 计算下一个索引
size_t swrq_nextindex(swr_queue_t *queue, size_t idx) {
    return (idx + 1) % queue->size;
}
```

定义中带着一个mutex，这是因为我们要先写一个加锁的入队和出队，等下才好作性能评估。

环形队列是怎么工作的呢？网上其实已经有很多资料，不过这里我还是再啰嗦一下好了。

- 环形队列是用一个数组，一个头索引和一个尾索引来模拟环状的队列。入队就是移动尾索引，出队就是移动头索引，当索引到达数组边界时则跳回数组头。看起来就像头索引追着尾索引转圈圈一样。
- 当头索引和尾索引相等时，表示队列为空，如下图：



![img](https://pic1.zhimg.com/80/v2-340961246445237a07ca009201f139d0_720w.webp)

- 下面是队列有数据的情况：



![img](https://pic2.zhimg.com/80/v2-543285f1519ea16557426d1784a1e631_720w.webp)

- 当尾索引绕到头索引的“身后”一格时，表示队列满了，如下图：



![img](https://pic3.zhimg.com/80/v2-2ccbad36866b3fcd002efc7b1eab666e_720w.webp)

可以发现队列预留了一个格子不能放数据，用于区分空和满的情况。

有了这几个图例，再来看出队和入队的代码就一目了然了，这是有锁版本，有锁版本需要将atomic_size_t改为size_t，以便获得最佳性能：

```c
bool swrq_push3(swr_queue_t *queue, const swr_ele_t *ele) {
    pthread_mutex_lock(&queue->lock);
    bool succ = false;
    size_t ntail = swrq_nextindex(queue, queue->tail);  // 取队列尾下一个索引
    if (ntail != queue->head) {                         // 如果下一个索引等于队列头索引，表示队列满了
        queue->eles[queue->tail] = *ele;                // 元素入队
        queue->tail = ntail;                            // 修改队列尾索引
        succ = true;
    }
    pthread_mutex_unlock(&queue->lock);
    return succ;
}

bool swrq_pop3(swr_queue_t *queue, swr_ele_t *ele) {
    pthread_mutex_lock(&queue->lock);
    bool succ = false;
    if (queue->head != queue->tail) {                   // 如果队列头索引等于队列尾索引，表示队列是空的
        *ele = queue->eles[queue->head];                // 元素出队
        queue->head = swrq_nextindex(queue, queue->head);   // 修改队列头的索引
        succ = true;
    }
    pthread_mutex_unlock(&queue->lock);
    return succ;
}
```

接下来是原子操作版本：

```c
1   bool swrq_push(swr_queue_t *queue, const swr_ele_t *ele) {
2       size_t ctail = atomic_load(&queue->tail);       // 取队列尾的索引
3       size_t ntail = swrq_nextindex(queue, ctail);    // 取队列尾下一个索引
4       if (ntail != atomic_load(&queue->head)) {       // 如果下一个索引等于队列头索引，表示队列满了
5           queue->eles[ctail] = *ele;                  // 元素入队
6           atomic_store(&queue->tail, ntail);          // 修改队列尾索引
7           return true;
8       }
9       return false;
10  }
11  
12  bool swrq_pop(swr_queue_t *queue, swr_ele_t *ele) {
13      size_t chead = atomic_load(&queue->head);       // 取队列头的索引
14      if (chead != atomic_load(&queue->tail)) {       // 如果队列头索引等于队列尾索引，表示队列是空的
15          *ele = queue->eles[chead];                  // 元素出队
16          atomic_store(&queue->head, swrq_nextindex(queue, chead));   // 修改队列头的索引
17          return true;
18      }
19      return false;
20  }
```

入队的关键是是第5，6行，强顺序一致性的原子操作能够保证前后的代码不乱序，即`元素入队`这个操作一定是在`修改队列尾索引`之前发生的。这里要强调，所谓的先后顺序是对其他线程来说的，对本线程来说肯定是顺序的。所以当消费者线程(调用pop的那个线程)取到的是更新后的尾索引时，它看到的新元素肯定已经入队。

同样的出队的关键是第15,16行，也是通过原子操作来保证出队和修改队列头索引的顺序性。

由于最多只有一个写线程和一个读线程，所以完全不需要CAS操作。现在可以来写一些代码测试一下有锁有无锁的性能区别：

```c
typedef bool (*push_fn_t)(swr_queue_t*, const swr_ele_t*);
typedef bool (*pop_fn_t)(swr_queue_t*, swr_ele_t*);

// 线程参数
typedef struct thead_arg {
    swr_queue_t *queue;
    char type;
    push_fn_t push;
    pop_fn_t pop;
} thead_arg_t;


// 计时器: 毫秒
double time_diff(struct timespec *start, struct timespec *end) {
    long sec = end->tv_sec - start->tv_sec;
    long nsec = end->tv_nsec - start->tv_nsec;
    return sec * 1000.0 + nsec / 1000000.0;
}

void* thread_func(void *a) {
    thead_arg_t *arg = (thead_arg_t*)a;
    swr_queue_t *queue = arg->queue;

    struct timespec time1, time2;
    clock_gettime(CLOCK_THREAD_CPUTIME_ID, &time1);

    if (arg->type == 'W') { // Producer
        swr_ele_t e = 10000000;
        while (true) {
            if (arg->push(queue, &e)) {
                if ((--e) < 0) break;
            }
        }       
    } else {        // Consumer
        swr_ele_t e;
        while (true) {
            if (arg->pop(queue, &e)) {
                // if (e % 1000000 == 0) printf("pop ele: %d\n", e);
                if (e == 0) break;
            }
        }
    }

    clock_gettime(CLOCK_THREAD_CPUTIME_ID, &time2);
    printf("%c Thread, Time=%fms\n", arg->type, time_diff(&time1, &time2));
    return NULL;
}

int main(int argc, char const *argv[])
{
    struct test_case {
        push_fn_t push;
        pop_fn_t pop;
        const char *desc;
    } 
    cases[] = {
        {swrq_push, swrq_pop, "atomic, seq_cst"},
        {swrq_push3, swrq_pop3, "mutex lock"},
    };

    for (int k = 0; k < sizeof(cases) / sizeof(cases[0]); ++k) {
        printf("----------------------------------------------------------------------------\n");
        printf("%s\n", cases[k].desc);
        swr_queue_t queue;
        swrq_init(&queue, 100);
        const int NUM = 2;
        pthread_t tids[NUM];
        thead_arg_t args[NUM];

        int i;
        for (i = 0; i < NUM; ++i) {
            args[i].queue = &queue;
            args[i].type = i == 0 ? 'W' : 'R';
            args[i].push = cases[k].push;
            args[i].pop = cases[k].pop;
            pthread_create(&tids[i], NULL, thread_func, args+i);
        }
        for (i = 0; i < NUM; ++i)
            pthread_join(tids[i], NULL);
        swrq_free(&queue);
    }
    return 0;
}
```

大体逻辑是分别对有锁和无锁版本，创建两个线程，一个向队列写，一个从队列读；入队和出队的次数分别是1000W次；开启O2优化编译，最后在我的WSL环境下得到的结果是：

```text
----------------------------------------------------------------------------
atomic, seq_cst
R Thread, Time=515.625000ms
W Thread, Time=515.625000ms
----------------------------------------------------------------------------
mutex lock
W Thread, Time=2000.000000ms
R Thread, Time=1984.375000ms
```

另外在我的MacOS，云服务器上测试的结果都差不多。这说明无锁版本比有锁版本快了将近4倍。

那还能不能更快一些呢？答案是可以的，上面的原子操作默认使用的是最严格的内存模型，即`__ATOMIC_SEQ_CST`，这个模式下很多编译器的优化都会被禁止。在我们以前的文章中，有介绍过[内存一致性模型](https://zhuanlan.zhihu.com/p/91406250)，其中有特别适合于读写的模型：`release/acquire`，我们先把代码改成更宽松的内存模式：

```c
1   bool swrq_push2(swr_queue_t *queue, const swr_ele_t *ele) {
2       size_t ctail = atomic_load_explicit(&queue->tail, memory_order_relaxed);
3       size_t ntail = swrq_nextindex(queue, ctail);
4       if (ntail != atomic_load_explicit(&queue->head, memory_order_acquire)) {
5           queue->eles[ctail] = *ele;
6           atomic_store_explicit(&queue->tail, ntail, memory_order_release);
7           return true;
8       }
9       return false;
10  }
11  
12  bool swrq_pop2(swr_queue_t *queue, swr_ele_t *ele) {
13      size_t chead = atomic_load_explicit(&queue->head, memory_order_relaxed);
14      if (chead != atomic_load_explicit(&queue->tail, memory_order_acquire)) {
15          *ele = queue->eles[chead];
16          atomic_store_explicit(&queue->head, swrq_nextindex(queue, chead), memory_order_release);
17          return true;
18      }
19      return false;
20  }
```

- 第2行使用的是`memory_order_relaxed`，这是最宽松的模式，它只保证变量加载的原子性。这里可以使用是因为只有生产者线程会调用push函数，而只有push函数会更新tail；也就是说第2行这个load不依赖于其他线程，所以可以用最宽松的模式。
- 这里最关键的是第6行和第14行，push线程使用`memory_order_release`模式写tail, pop线程则使用`memory_order_acquire`模式读tail，这两个模式成对使用，release用于写，acquire用于读。假设push线程写完tail后，pop线程读出了最新的tail，那么在这一刻，pop线程一定能观察到push线程写tail**之前的那些内存变化**。所以pop线程接下来取的元素一定是对的。
- 第4行和第16行也是类似的逻辑。

现在，我们把这两个函数加入测试中，并得到测试数据：

```text
----------------------------------------------------------------------------
atomic, seq_cst
R Thread, Time=515.625000ms
W Thread, Time=515.625000ms
----------------------------------------------------------------------------
atomic, release/acquire/relaxed
R Thread, Time=312.500000ms
W Thread, Time=312.500000ms
----------------------------------------------------------------------------
mutex lock
W Thread, Time=2000.000000ms
R Thread, Time=1984.375000ms
```

从结果上看`release/acquire`的原子操作比`seq_cst`的提高了1.6倍，是有锁版本的6倍左右，这个提升相当的明显。

基于原子操作的无锁队列到这儿就完成了，虽然它有一些限制，但是在它派上用场的时候，一定能发挥出可观的性能优势。

编辑于 2021-03-31 23:50

[服务器编程](https://www.zhihu.com/topic/19982921)

[并行计算](https://www.zhihu.com/topic/19582194)

[C / C++](https://www.zhihu.com/topic/19601705)