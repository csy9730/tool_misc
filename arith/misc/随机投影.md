# 随机投影

[随机投影](https://www.zhihu.com/search?q=随机投影&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1148832134})（Random Projection）算法。

实际上在我看来，无论是完美哈希，Karger的最小切，还是快排快选都是理论复杂，实现简单的算法，但是毫无疑问Random Projection最具有代表性。

学习机器学习的小伙伴都清楚，由于高维度空间的数据点极其稀疏（Curse of Dimensionality），导致高维度空间下计算[欧式距离](https://www.zhihu.com/search?q=欧式距离&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1148832134})会极其耗费算力。通常为了解决高维度空间的问题，我们会选择降低维度，但是常见的SVD本身算法复杂度也很高，如果说计算十几维度SVD还有一战之力，但是更高维度情况下SVD的表现就很差强人意了。

而[Random Projection算法](https://www.zhihu.com/search?q=Random+Projection算法&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1148832134})则非常巧妙的解决了这个问题，并且实现起来非常简单，有多简单呢？来举个例子：

假设我们有一篇英文论文 ![[公式]](https://www.zhihu.com/equation?tex=q) ，一般来说，自然语言相关的问题维度都非常高，我们假设这篇论文有10000维，那么计算 ![[公式]](https://www.zhihu.com/equation?tex=q) 与其他论文的[欧氏距离](https://www.zhihu.com/search?q=欧氏距离&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1148832134})（假设我们用Nearest Neighbor来考虑相似度）则必须要计算这10000维。Random Peojection告诉我们，你完全不需要计算10000维度，你只需要三步：

1. 挑一个自己喜欢的数字50，100，200，233，都随你开心，
2. 以[高斯分布](https://www.zhihu.com/search?q=高斯分布&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1148832134})随机选取任N（N为前面选取得数字）个坐标，
3. 将数据点投射到新的坐标上，根据新的向量计算相似度即可。

神奇的是，经过Random Projection算法降维之后的结果与不降维的结果几乎是一样的。

以下原理极其枯燥，请慎重观看！！！

将[随机变量](https://www.zhihu.com/search?q=随机变量&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1148832134}) ![[公式]](https://www.zhihu.com/equation?tex=%28X+-+E%28X%29%29%5E%7B2%7D+%5Cgeq+0)

代入马尔可夫不等式![[公式]](https://www.zhihu.com/equation?tex=P%28X+%5Cgeq+t%29+%5Cleq+%5Cfrac%7BE%28X%29%7D%7Bt%7D)

可得：

![[公式]](https://www.zhihu.com/equation?tex=P%28%7CX+-+E%28X%29%7C+%5Cgeq+%5Cvarepsilon%29+%3DP%28%28X-E%28X%29%29%5E%7B2%7D%3E%5Cvarepsilon%5E%7B2%7D%29+%5Cleq+%5Cfrac%7BE%28%28X-E%28X%29%29%5E%7B2%7D%29%7D%7B%5Cvarepsilon%5E%7B2%7D%7D+%3D+%5Cfrac%7BV%28X%29%7D%7B%5Cvarepsilon%5E%7B2%7D%7D)

即切比雪夫不等式：

![[公式]](https://www.zhihu.com/equation?tex=P%28%7CX+-+E%28X%29%7C+%5Cgeq+%5Cvarepsilon%29++%5Cleq++%5Cfrac%7BV%28X%29%7D%7B%5Cvarepsilon%5E%7B2%7D%7D)

我们假设有 ![[公式]](https://www.zhihu.com/equation?tex=n) 个随机的**独立**采样 ![[公式]](https://www.zhihu.com/equation?tex=x_1%2Cx_2%2C...%2Cx_n) ，我们可以期待这些随机采样的期望是会非常接近变量 ![[公式]](https://www.zhihu.com/equation?tex=X) 本身的期望 ![[公式]](https://www.zhihu.com/equation?tex=E%28X%29) 。根据大数定理，我们可以限定其期望距离 ![[公式]](https://www.zhihu.com/equation?tex=E%28X%29) 的距离大于某一数值 ![[公式]](https://www.zhihu.com/equation?tex=%5Cvarepsilon) 的概率为：

![[公式]](https://www.zhihu.com/equation?tex=P%28%7C%5Cfrac%7Bx_1%2Bx_2%2B...%2Bx_n%7D%7Bn%7D+-+E%28X%29%7C+%5Cgeq+%5Cvarepsilon%29++%5Cleq++%5Cfrac%7BV%28X%29%7D%7Bn%5Cvarepsilon%5E%7B2%7D%7D)

现在，让我们来考虑一下，如果使用一个均值 ![[公式]](https://www.zhihu.com/equation?tex=E%28X%29+%3D+0) 方差 ![[公式]](https://www.zhihu.com/equation?tex=v+%3D+1%2F2%5Cpi) [高斯随机变量](https://www.zhihu.com/search?q=高斯随机变量&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1148832134}) ![[公式]](https://www.zhihu.com/equation?tex=X) ，可得

![[公式]](https://www.zhihu.com/equation?tex=f_X%28x%29+%3D+%5Cfrac%7B1%7D%7B2%5Cpi+v%7De%5E%7B-%5Cfrac%7Bx%5E2%7D%7B2v%7D%7D+%3D+e%5E%7B-%5Cpi+x%5E2%7D)

这里有一个小的trick，即 ![[公式]](https://www.zhihu.com/equation?tex=E%28x%5E2%29+%3D+E%28%28X-E%28x%29%29%5E2%29+%3D+V%28X%29+%3D+1%2F2%5Cpi)

假设我们用变量 ![[公式]](https://www.zhihu.com/equation?tex=X) 来生成 一个 ![[公式]](https://www.zhihu.com/equation?tex=d) 维空间的坐标（通常 ![[公式]](https://www.zhihu.com/equation?tex=d) 的维度非常高），使用 ![[公式]](https://www.zhihu.com/equation?tex=%7Cx%7C+%3D+%5Csqrt%7Bx_1%5E2%2Bx_2%5E2%2B...%2Bx_d%5E2%7D) 来表示随机生成的坐标，根据之前的大数定理公式可得：

![[公式]](https://www.zhihu.com/equation?tex=P%28%7C%5Cfrac%7B%7Cx%7C%5E2%7D%7Bd%7D+-+V%28X%29%7C+%5Cgeq+%5Cvarepsilon%29++%5Cleq++%5Cfrac%7BV%28X%5E2%29%7D%7Bd%5Cvarepsilon%5E%7B2%7D%7D)

通过这个公式，我们不难发现，当 ![[公式]](https://www.zhihu.com/equation?tex=d) 很大的时候， ![[公式]](https://www.zhihu.com/equation?tex=%7Cx%7C%5Capprox+%5Csqrt%7B%5Cfrac%7Bd%7D%7B2%5Cpi%7D%7D+%3D+%5CTheta%28%5Csqrt%7Bd%7D%29) ，这一结论非常重要，他告诉我们，当我们以高斯分布在高维度空间取任意坐标点时，该坐标点与原点的距离为 ![[公式]](https://www.zhihu.com/equation?tex=%5CTheta%28%5Csqrt%7Bd%7D%29) 。

同时，如果我们以高斯分布任意取两点 ![[公式]](https://www.zhihu.com/equation?tex=x%EF%BC%8Cy) ，两点的点乘期望 :

![[公式]](https://www.zhihu.com/equation?tex=E%28%3Cx%2C+y%3E%29%3DE%28x_1y_1%2Bx_2y_2%2B...%2Bx_dy_d%29%3DdE%28XY%29%3DdE%28X%29E%28Y%29%3D0)

这一结论同样重要，这意味着高维度空间下我们取的任意两点几乎是**正交**的。下面让我们用更严谨一些的推理来证明这一点：

假设我们有一个维度为 ![[公式]](https://www.zhihu.com/equation?tex=d) ，半径为1的单位球（无法想象高维度空间的球或者圆是什么样子，所以就叫球好了），尽管我们不知道这个球的样子，但是我们可以通过积分来求出该球的体积 ![[公式]](https://www.zhihu.com/equation?tex=V%28d%29+%3D+%5Cint_%7B-1%7D%5E%7B1%7D%28%5Csqrt%7B1-x_1%5E2%7D%29%5E%7Bd-1%7DV%28d-1%29dx_1)

接下来，让我们根据该球的某一半径，选择一个常数 ![[公式]](https://www.zhihu.com/equation?tex=c) ，使得选定该半径上的某一坐标 ![[公式]](https://www.zhihu.com/equation?tex=x_1%5Cgeq%5Cfrac%7Bc%7D%7B%5Csqrt%7Bd-1%7D%7D) ，根据该坐标将[单位半球](https://www.zhihu.com/search?q=单位半球&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1148832134})分成两部分：

![img](https://pic1.zhimg.com/80/v2-d74a5e1e49ee60c15656eb06e1aa4751_1440w.jpg?source=1940ef5c)单位球

假设以 ![[公式]](https://www.zhihu.com/equation?tex=x_i) 为横切位置，则上部分球体积为：

![[公式]](https://www.zhihu.com/equation?tex=V_S+%3D+%5Cint_%7B%5Cfrac%7Bc%7D%7B%5Csqrt%7Bd-1%7D%7D%7D%5E%7B1%7D%28%5Csqrt%7B1-x_1%5E2%7D%29%5E%7Bd-1%7DV%28d-1%29dx_1)

利用不等式 ![[公式]](https://www.zhihu.com/equation?tex=1-x%5Cleq+e%5E%7B-x%7D%EF%BC%8C0%5Cleq+x%5Cleq+1) ，代入可得：

![[公式]](https://www.zhihu.com/equation?tex=V_S+%3C+%5Cint_%7B%5Cfrac%7Bc%7D%7B%5Csqrt%7Bd-1%7D%7D%7D%5E%7B1%7D%28e%5E%7B-x_1%5E2%7D%29%5E%7B%5Cfrac%7Bd-1%7D%7B2%7D%7DV%28d-1%29dx_1)

同时可根据 ![[公式]](https://www.zhihu.com/equation?tex=x_1%5Cgeq%5Cfrac%7Bc%7D%7B%5Csqrt%7Bd-1%7D%7D) 得 ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7Bx_1%5Csqrt%7Bd-1%7D%7D%7Bc%7D%3E1) ，即：

![[公式]](https://www.zhihu.com/equation?tex=V_S+%3C+%5Cint_%7B%5Cfrac%7Bc%7D%7B%5Csqrt%7Bd-1%7D%7D%7D%5E%7B1%7D%5Cfrac%7Bx_1%5Csqrt%7Bd-1%7D%7D%7Bc%7D%28e%5E%7B-x_1%5E2%7D%29%5E%7B%5Cfrac%7Bd-1%7D%7B2%7D%7DV%28d-1%29dx_1) ，此时，替换 ![[公式]](https://www.zhihu.com/equation?tex=u%3Dx_1%5E2%2Cdu+%3D+2x_1dx_1) ，计算之后得到：

![[公式]](https://www.zhihu.com/equation?tex=V_S+%3C+%5Cint_%7B%5Cfrac%7Bc%7D%7B%5Csqrt%7Bd-1%7D%7D%7D%5E%7B1%7D%5Cfrac%7Bx_1%5Csqrt%7Bd-1%7D%7D%7Bc%7D%28e%5E%7B-x_1%5E2%7D%29%5E%7B%5Cfrac%7Bd-1%7D%7B2%7D%7DV%28d-1%29dx_1%3D%5Cfrac%7B1%7D%7Bc%5Csqrt%7Bd-1%7D%7DV%28d-1%29e%5E%7B-%5Cfrac%7Bc%5E2%7D%7B2%7D%7D)

再来计算该单位半球的下半部份：

![[公式]](https://www.zhihu.com/equation?tex=V_C+%3D+V%28d-1%29%281-%5Cfrac%7B1%7D%7Bd-1%7D%29%5E%7B%5Cfrac%7Bd-1%7D%7B2%7D%7D%5Cfrac%7B1%7D%7B%5Csqrt%7Bd-1%7D%7D)

此时再根据不等式 ![[公式]](https://www.zhihu.com/equation?tex=%5Cforall+%5Calpha%5Cgeq+1%2C+++%5Cforall+0%3Cx%3C1) ， ![[公式]](https://www.zhihu.com/equation?tex=%281-x%29%5E%5Calpha+%5Cgeq+1-%5Calpha+x) ，令 ![[公式]](https://www.zhihu.com/equation?tex=%5Calpha+%3D+%28d-1%29%2F2) ，可得：

![[公式]](https://www.zhihu.com/equation?tex=V_C+%3D+V%28d-1%29%281-%5Cfrac%7B1%7D%7Bd-1%7D%29%5E%7B%5Cfrac%7Bd-1%7D%7B2%7D%7D%5Cfrac%7B1%7D%7B%5Csqrt%7Bd-1%7D%7D+%5Cgeq+V%28d-1%29%5Cfrac%7B1%7D%7B2%5Csqrt%7Bd-1%7D%7D)

综合以上结论，我们可以得到，单位半球上半部分的体积 ![[公式]](https://www.zhihu.com/equation?tex=V_S) 与半球的体积 ![[公式]](https://www.zhihu.com/equation?tex=V_H) 的比例满足：

![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7BV_S%7D%7BV_H%7D%3C%5Cfrac%7B%5Cfrac%7B1%7D%7Bc%5Csqrt%7Bd-1%7D%7DV%28d-1%29e%5E%7B-%5Cfrac%7Bc%5E2%7D%7B2%7D%7D%7D%7BV%28d-1%29%5Cfrac%7B1%7D%7B2%5Csqrt%7Bd-1%7D%7D%7D%3D%5Cfrac%7B2%7D%7Bc%7De%5E%7B-%5Cfrac%7Bc%5E2%7D%7B2%7D%7D)

当我们把他们的体积比想象成任意取点的概率比，即可得到结论:

当我们在单位球内随机取点的时候，该点的某一坐标 ![[公式]](https://www.zhihu.com/equation?tex=x_i%5Cgeq+%5Cfrac%7Bc%7D%7B%5Csqrt%7Bd-1%7D%7D) 的概率不大于 ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7B2%7D%7Bc%7De%5E%7B-%5Cfrac%7Bc%5E2%7D%7B2%7D%7D) 。

即可得结论，一个高维度的单位球，其大部分体积都在 ![[公式]](https://www.zhihu.com/equation?tex=%5B-x_1%2Cx_1%5D) 区间内。

同时，注意到 ![[公式]](https://www.zhihu.com/equation?tex=V%28d%29+-+r%5EdV%28d%29+%3D+V%28d%29%281-r%5Ed%29) ，即维度足够高的时候，即使所取坐标 ![[公式]](https://www.zhihu.com/equation?tex=x_i) 非常接近1，其体积也占据了该单位球总体积的大部分。如果我们任取一点 ![[公式]](https://www.zhihu.com/equation?tex=x) ，将这两点投影到单位球的半径（注意[半径长度](https://www.zhihu.com/search?q=半径长度&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1148832134})为1）上，可以得到两点在该半径上的投影很大概率为 ![[公式]](https://www.zhihu.com/equation?tex=%5CTheta%281%2F%5Csqrt%7Bd%7D%29) 。显而易见，当 ![[公式]](https://www.zhihu.com/equation?tex=d) 很大的时候， ![[公式]](https://www.zhihu.com/equation?tex=x) 与半径几乎正交，由此我们可以得到两个结论：

1. 我们在高维度单位球里任取两点 ![[公式]](https://www.zhihu.com/equation?tex=x_1%2Cx_2) ，这两点距离原点的距离几乎为1。
2. 同时，有我们之前得到的结论，如果把其中一个点当作半径，另外一个点与第一个点几乎正交，即 ![[公式]](https://www.zhihu.com/equation?tex=x_1%2Cx_2) 几乎正交

公式有点多，先写这么多，如果有人看的话再更新，剩下的还有高维度空间的部分性质，随机投影理论，[高斯环理论](https://www.zhihu.com/search?q=高斯环理论&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1148832134})，JL-Lemma。

![img](https://pic1.zhimg.com/80/v2-0262993ce091104799c7a234b6ba9e13_1440w.jpg?source=1940ef5c)

资料来源：

Blum A, Hopcroft J, Kannan R. Foundations of data science[M]. Cambridge University Press, 2020.

[发布于 2020-04-13 01:20](https://www.zhihu.com/question/27940474/answer/1148832134)