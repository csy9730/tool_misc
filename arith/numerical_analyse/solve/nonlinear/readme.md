# readme



## 一元求解

### 二分法

基本原理就是《高等数学》中的 零点定理：只要连续函数在一个闭区间上端点的函数值异号，那么在这个闭区间内至少存在一个零点。

对这个区间进行二分，每次迭代都使区间长度缩小一半，始终保持两个端点函数值异号，当然这样能够求出一个解，所以为了保证在二分的过程中不漏解，需要保证区间内只存在唯一解。保证方法就是保证函数在区间内单调。

### 0.618法
黄金分割法
### 斐波那契数列法

### 牛顿法
解方程.
$$
f(x) = 0
$$

牛顿法求解方程
$$
x_{k+1} = x_k - \frac{f(x_k)}{f^`(x_k)}
$$
#### 函数极值
$$
x = arg min f(x)
$$
牛顿法求解函数极值
$$
x_{k+1} = x_k - \frac{f^`(x_k)}{f^{``}(x_k)}
$$

### 弦切法
弦切法/割线法/弦截法 Secant Method


割线法的公式可以由Newton迭代法推导出来。


### 抛物线法

### 不动点迭代法
通用方法，需要用户自行构造不动点函数
### 斯蒂芬森迭代法
可以加速迭代法

## 多元线性方程组求解

### jacobi迭代法
也被叫做简单迭代法
### 高斯-赛德尔迭代法
jacobi迭代法的改进方法

### 松弛迭代法
高斯-赛德尔迭代法的改进方法，引入了松弛因子w（记忆因子）

$$
x_i^{(k+1)}=(1-\omega)x_i^{(k)}+\frac{\omega}{a_{ii}}(b_i-\sum_{j=1}^{i-1}{a_{ij}x_j^{(k+1)}}-\sum_{j=i+1}^n{a_{ij}x_j^{(k)}})
$$


- w>1 超松弛迭代法 SOR 
- w=1 高斯-赛德尔迭代法
- w<1 低松弛迭代法


## 多元非线性求解



### 牛顿法

计算jacobi矩阵，然后求逆 。


### 拟牛顿法

拟牛顿法（避免求解Hessian矩阵）
- DFP算法
- BFGS算法
#### 变尺度法
#### DFP算法
#### BFGS
#### L-BFGS
对于 BFGS 算法，需要储存近似逆二阶导数矩阵 [公式] ，对于维度较大的问题不再适用，因此有了内存受限的 BFGS 算法 （Limited-memory BFGS）
#### Powell方法

## misc

注意事项：牛顿法，弦切法和抛物线法可能超出输入有效范围，二分法和0.618法不会超出范围。 

例如： 优化函数包含 sqrt(x) 项时，在靠近0处，导数为无穷，所以牛顿法的更新结果可能小于0，超出定义域。
### base
#### 线性收敛
e表示迭代过程的误差

$$
\lim \frac{e_{i+1}}{e_i} = S <1
$$

线性收敛，收敛速度为S

二分法的S是1/2 

#### 二阶收敛
$$
\lim \frac{e_{i+1}}{e_i^2} = M
$$

#### 凸函数
Convex Optimization——凸函数

$
f(\theta x+(1-\theta )y) <= \theta f(x) + (1-\theta )f(y), \theta \in (0,1)
$

一个函数是严格凸函数当且仅当条件二当且仅当 x==y 时才取等号。


凸函数的几何意义在于，定义域中任意两点连线组成的线段都在这两点的函数曲线（面）上方。由凸函数的定义可以类似地引出凹函数的定义：如果函数 f(x) 是凸函数，那么函数$-f(x)$是凹函数。

#### 一阶条件
一阶条件有清晰的几何意义：凸函数永远位于其切线的上方。
$$
f(y)>=f(x) + \nabla f(x)^T(y-x)
$$
#### 二阶条件

现在我们假设函数  是二阶可微的，即函数  的Hessian矩阵在定义域内处处存在，那么函数  是凸函数当且仅当对于定义域内的任意一点  ，该点处的Hessian矩阵是半正定的

$$
\nabla ^2 f(x)>=0
$$

#### 3

- 指数函数：$e^x$是 凸函数 。
- 幂函数： $x^a$, 当a>=1或a<0 时是凸函数，当$0<=a<1$  是凹函数。
- 对数函数： $log x$ 是凹函数。
- 负熵函数：$xlogx$  是凸函数。