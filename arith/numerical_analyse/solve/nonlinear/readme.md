# readme


## 一元求解

### 二分法

基本原理就是《高等数学》中的 零点定理：只要连续函数在一个闭区间上端点的函数值异号，那么在这个闭区间内至少存在一个零点。

对这个区间进行二分，每次迭代都使区间长度缩小一半，始终保持两个端点函数值异号，当然这样能够求出一个解，所以为了保证在二分的过程中不漏解，需要保证区间内只存在唯一解。保证方法就是保证函数在区间内单调。

### 0.618法
黄金分割法
### 斐波那契数列法

### 牛顿法
解方程.
$$
f(x) = 0
$$

牛顿法求解方程
$$
x_{k+1} = x_k - \frac{f(x_k)}{f^`(x_k)}
$$
#### 函数极值
$$
x = arg min f(x)
$$
牛顿法求解函数极值
$$
x_{k+1} = x_k - \frac{f^`(x_k)}{f^{``}(x_k)}
$$

### 弦切法
弦切法/割线法/弦截法 Secant Method


割线法的公式可以由Newton迭代法推导出来。


### 抛物线法

### 不动点迭代法
通用方法，需要用户自行构造不动点函数
### 斯蒂芬森迭代法
可以加速迭代法

## 多元线性方程组求解

### jacobi迭代法
也被叫做简单迭代法
### 高斯-赛德尔迭代法
jacobi迭代法的改进方法

### 松弛迭代法
高斯-赛德尔迭代法的改进方法，引入了松弛因子w（记忆因子）

$$
x_i^{(k+1)}=(1-\omega)x_i^{(k)}+\frac{\omega}{a_{ii}}(b_i-\sum_{j=1}^{i-1}{a_{ij}x_j^{(k+1)}}-\sum_{j=i+1}^n{a_{ij}x_j^{(k)}})
$$


- w>1 超松弛迭代法 SOR 
- w=1 高斯-赛德尔迭代法
- w<1 低松弛迭代法


## 多元非线性求解



### 牛顿法

计算jacobi矩阵，然后求逆 。


### 拟牛顿法

拟牛顿法（避免求解Hessian矩阵）
- DFP算法
- BFGS算法
#### 变尺度法
#### DFP算法
#### BFGS
#### L-BFGS
对于 BFGS 算法，需要储存近似逆二阶导数矩阵 [公式] ，对于维度较大的问题不再适用，因此有了内存受限的 BFGS 算法 （Limited-memory BFGS）
#### Powell方法

## misc

注意事项：牛顿法，弦切法和抛物线法可能超出输入有效范围，二分法和0.618不会超出范围。 

例如： 优化函数包含 sqrt(x) 项时，在靠近0处，导数为无穷，所以牛顿法的更新结果可能小于0，超出定义域。
